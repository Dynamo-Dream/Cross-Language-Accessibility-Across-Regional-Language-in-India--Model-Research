{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T10:29:07.677360Z","iopub.execute_input":"2024-11-30T10:29:07.677693Z","iopub.status.idle":"2024-11-30T10:29:08.659298Z","shell.execute_reply.started":"2024-11-30T10:29:07.677665Z","shell.execute_reply":"2024-11-30T10:29:08.658338Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\nfrom fairseq.models.text_to_speech.hub_interface import TTSHubInterface\nimport IPython.display as ipd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T10:30:34.903486Z","iopub.execute_input":"2024-11-30T10:30:34.903849Z","iopub.status.idle":"2024-11-30T10:31:03.302811Z","shell.execute_reply.started":"2024-11-30T10:30:34.903820Z","shell.execute_reply":"2024-11-30T10:31:03.302005Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install fairseq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T10:29:34.849244Z","iopub.execute_input":"2024-11-30T10:29:34.849841Z","iopub.status.idle":"2024-11-30T10:30:30.081851Z","shell.execute_reply.started":"2024-11-30T10:29:34.849807Z","shell.execute_reply":"2024-11-30T10:30:30.080623Z"}},"outputs":[{"name":"stdout","text":"Collecting fairseq\n  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.16.0)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq) (3.0.10)\nCollecting hydra-core<1.1,>=1.0.7 (from fairseq)\n  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\nCollecting omegaconf<2.1 (from fairseq)\n  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.26.4)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq) (2024.5.15)\nCollecting sacrebleu>=1.4.12 (from fairseq)\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fairseq) (4.66.4)\nCollecting bitarray (from fairseq)\n  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\nRequirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.4.0)\nCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (6.0.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (4.12.2)\nCollecting portalocker (from sacrebleu>=1.4.12->fairseq)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (5.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq) (2.22)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->fairseq) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fairseq) (1.3.0)\nDownloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: fairseq, antlr4-python3-runtime\n  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10414540 sha256=247e8ee8da48cbacca04c29c58fd5f501339327b0d7f6bbbb8061fed268f5433\n  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=200e7b1dde36eef54c4d93db83c0186f518c9b1cea8aa6b50fbe26798f50ccaf\n  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\nSuccessfully built fairseq antlr4-python3-runtime\n\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, fairseq\nSuccessfully installed antlr4-python3-runtime-4.8 bitarray-3.0.0 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-3.0.0 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"models, cfg, task = load_model_ensemble_and_task_from_hf_hub(\n    \"facebook/fastspeech2-en-ljspeech\",\n    arg_overrides={\"vocoder\": \"hifigan\", \"fp16\": False}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T10:31:19.468246Z","iopub.execute_input":"2024-11-30T10:31:19.469383Z","iopub.status.idle":"2024-11-30T10:31:23.587191Z","shell.execute_reply.started":"2024-11-30T10:31:19.469346Z","shell.execute_reply":"2024-11-30T10:31:23.586170Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6343c10758041dba5ea5efceabadb27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ab9103fb05947de9c41161414d764ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"run_fast_speech_2.py:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f787ff6ce4b84a98905ce53c4aff6eab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"fbank_mfa_gcmvn_stats.npz:   0%|          | 0.00/1.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07e7d96ff9c94522a35d697fdc5702c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hifigan.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d3b8e60a62641c49a4431a3b8f04235"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99825547e8314d34928277f4f35720fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hifigan.bin:   0%|          | 0.00/55.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7676bef27a8440c4968c837ee2b235bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.pt:   0%|          | 0.00/495M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f6a3ba61998427897a26fc5ecb39c83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.yaml:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93309a561e9e4482a245ba6775cabb50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/602 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f6ac05177564966a5ffa887d5c2f14c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model = models[0]\nTTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)\ngenerator = task.build_generator(model, cfg)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T10:31:34.433175Z","iopub.execute_input":"2024-11-30T10:31:34.433534Z","iopub.status.idle":"2024-11-30T10:31:35.113057Z","shell.execute_reply.started":"2024-11-30T10:31:34.433503Z","shell.execute_reply":"2024-11-30T10:31:35.111842Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\n/opt/conda/lib/python3.10/site-packages/fairseq/models/text_to_speech/vocoder.py:191: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(checkpoint_path)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m TTSHubInterface\u001b[38;5;241m.\u001b[39mupdate_cfg_with_data_cfg(cfg, task\u001b[38;5;241m.\u001b[39mdata_cfg)\n\u001b[0;32m----> 3\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fairseq/tasks/text_to_speech.py:151\u001b[0m, in \u001b[0;36mTextToSpeechTask.build_generator\u001b[0;34m(self, models, cfg, vocoder, **unused)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vocoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     vocoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_default_vocoder()\n\u001b[0;32m--> 151\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNON_AUTOREGRESSIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NonAutoregressiveSpeechGenerator(model, vocoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cfg)\n","\u001b[0;31mTypeError\u001b[0m: 'FastSpeech2Model' object is not subscriptable"],"ename":"TypeError","evalue":"'FastSpeech2Model' object is not subscriptable","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"text = \"Space exploration has always been a source of fascination for humanity. From the first moon landing to the latest Mars rover missions, each step forward expands our understanding of the universe\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T10:32:28.604336Z","iopub.execute_input":"2024-11-30T10:32:28.604708Z","iopub.status.idle":"2024-11-30T10:32:28.609087Z","shell.execute_reply.started":"2024-11-30T10:32:28.604680Z","shell.execute_reply":"2024-11-30T10:32:28.608092Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"sample = TTSHubInterface.get_model_input(task, text)\nwav, rate = TTSHubInterface.get_prediction(task, model, generator, sample)\n\nipd.Audio(wav, rate=rate)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}